<h3>Prompt Injection - Sched-yule conflict (Day 8)</h3>

Day 8 teaches the concept of prompt injection. The room explains how Large Language Models (LLMs) act and how to use agentic AI's Chain-of-thought reasoning to exploit a broswer-based application. Participants are able to put this into practice by interacting with and exploiting a holiday-themed AI agent in TryHackMe's virtual machines.

<h4>Concepts Explored:</h4>

- Prompt Injection
- Large Language Models (LLMs)
- Agentic AI

<h4>Tools Used:</h4>

- Ubuntu Virtual Machine
- Firefox Web Browser

[Link to Room](https://tryhackme.com/room/promptinjection-aoc2025-sxUMnCkvLO)

<br/>
<img width="844" height="1220" alt="image" src="https://github.com/user-attachments/assets/b862c5a2-0665-4d70-bcc6-3754c3d5daa0" />
